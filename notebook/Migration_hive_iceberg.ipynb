{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b570afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.bool = np.bool_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57dede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\" \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"admin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"admin123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89179475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x104df5d50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# Set Spark configuration\n",
    "conf = SparkConf()\n",
    "conf.set(\n",
    "    \"spark.jars.packages\",\n",
    "    \"org.apache.hadoop:hadoop-aws:3.3.1,\"\n",
    "    \"org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:1.3.0,\"\n",
    "    \"org.projectnessie:nessie-spark-extensions-3.3_2.12:0.44.0,\"\n",
    "    \"software.amazon.awssdk:bundle:2.17.178,\"\n",
    "    \"software.amazon.awssdk:url-connection-client:2.17.178\"\n",
    ")\n",
    "conf.set(\n",
    "    \"spark.sql.extensions\",\n",
    "    \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\n",
    ")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.type\",\"hive\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
    "# Ensure Python <-> Java interactions are with PyArrow\n",
    "conf.set(\"spark.sql.execution.pyarrow.enabled\", \"true\")\n",
    "\n",
    "# Set Hive support configuration\n",
    "conf.set(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "\n",
    "# Set the Hive metastore URI to point to the external CDP cluster\n",
    "conf.set(\"hive.metastore.uris\", \"thrift://51.15.202.128:9083\")\n",
    "\n",
    "\n",
    "\n",
    "conf.set('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "# set the location of the nessie server\n",
    "conf.set('spark.sql.catalog.iceberg.uri', \"http://212.47.236.230:19120/api/v1\")\n",
    "# default branch for Nessie catalog to work on\n",
    "conf.set('spark.sql.catalog.iceberg.ref', 'main')\n",
    "# use no authorization. Options are NONE AWS BASIC and aws implies running Nessie on a lambda\n",
    "conf.set('spark.sql.catalog.iceberg.authentication.type', 'NONE')\n",
    "# tell the nessie that its a Nessie catalog\n",
    "conf.set('spark.sql.catalog.iceberg.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "\n",
    "conf.set('spark.sql.catalog.iceberg.s3.endpoint', \"http://212.47.236.230:9000\")\n",
    "# set the location for Nessie catalog to store data. Spark writes to this directory\n",
    "conf.set('spark.sql.catalog.iceberg.warehouse', \"s3a://warehouse/tablespace/external/hive/tpcds_10000_parquet.db\")\n",
    "conf.set('spark.sql.catalog.iceberg.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "\n",
    "\n",
    "conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "conf.set(\"spark.sql.warehouse.dir\", \"s3a://warehouse/tablespace/external/hive/tpcds_10000_parquet.db/\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"http://212.47.236.230:9000\")  # Add your S3 endpoint here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380acfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/07/02 11:48:12 WARN Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.2.35 instead (on interface en0)\n",
      "24/07/02 11:48:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/Ziad/anaconda3/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/Ziad/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/Ziad/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.3_2.12 added as a dependency\n",
      "org.projectnessie#nessie-spark-extensions-3.3_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-40adcc08-197a-43f0-88df-2c789726257f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in local-m2-cache\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.3_2.12;1.3.0 in central\n",
      "\tfound org.projectnessie#nessie-spark-extensions-3.3_2.12;0.44.0 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.17 in central\n",
      "\tfound org.projectnessie#nessie-spark-extensions-grammar;0.44.0 in central\n",
      "\tfound org.projectnessie#nessie-spark-antlr-runtime;0.44.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.11.1 in central\n",
      "\tfound org.projectnessie#nessie-spark-extensions-base_2.12;0.44.0 in central\n",
      "\tfound org.projectnessie#nessie-client;0.30.0 in central\n",
      "\tfound org.projectnessie#nessie-model;0.30.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache\n",
      "\tfound software.amazon.awssdk#bundle;2.17.178 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#utils;2.17.178 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.17.178 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in local-m2-cache\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.17.178 in central\n",
      ":: resolution report :: resolve 1321ms :: artifacts dl 55ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]\n",
      "\torg.antlr#antlr4-runtime;4.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.3_2.12;1.3.0 from central in [default]\n",
      "\torg.projectnessie#nessie-client;0.30.0 from central in [default]\n",
      "\torg.projectnessie#nessie-model;0.30.0 from central in [default]\n",
      "\torg.projectnessie#nessie-spark-antlr-runtime;0.44.0 from central in [default]\n",
      "\torg.projectnessie#nessie-spark-extensions-3.3_2.12;0.44.0 from central in [default]\n",
      "\torg.projectnessie#nessie-spark-extensions-base_2.12;0.44.0 from central in [default]\n",
      "\torg.projectnessie#nessie-spark-extensions-grammar;0.44.0 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.17 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from local-m2-cache in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from local-m2-cache in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   22  |   0   |   0   |   0   ||   22  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-40adcc08-197a-43f0-88df-2c789726257f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 22 already retrieved (0kB/30ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/07/02 11:48:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n",
      "24/07/02 11:48:22 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|                 air|\n",
      "|bi_modeling_test_...|\n",
      "|             default|\n",
      "|  default_mart_covid|\n",
      "|   default_reference|\n",
      "|default_staging_c...|\n",
      "|             iceberg|\n",
      "|  information_schema|\n",
      "|          nemo_delta|\n",
      "|                 sys|\n",
      "| tpcds_10000_parquet|\n",
      "|    tpcds_10000_text|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----------+\n",
      "|namespace|          tableName|isTemporary|\n",
      "+---------+-------------------+-----------+\n",
      "|  default|         land_yousr|      false|\n",
      "|  default|         land_gab22|      false|\n",
      "|  default|     land_gab_abstr|      false|\n",
      "|  default|        land_getfac|      false|\n",
      "|  default|        land_getvir|      false|\n",
      "|  default|         land_solde|      false|\n",
      "|  default|              yousr|      false|\n",
      "|  default|     land_customers|      false|\n",
      "|  default|               test|      false|\n",
      "|  default|             ice_v2|      false|\n",
      "|  default|external_callcenter|      false|\n",
      "|  default|          inventory|      false|\n",
      "|  default|       catalog_page|      false|\n",
      "|  default|         inventoryy|      false|\n",
      "|  default|        exinventory|      false|\n",
      "|  default|      sales_target1|      false|\n",
      "|  default|   raw_covid__cases|      false|\n",
      "|  default|raw_covid__vaccines|      false|\n",
      "|  default|       sample_table|      false|\n",
      "+---------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CDP Cluster Connection\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Running\")\n",
    "\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "\n",
    "spark.sql(\"USE default\")\n",
    "\n",
    "spark.sql(\"SHOW TABLES\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec1b0e",
   "metadata": {},
   "source": [
    "### Describe and fetch hive tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d613b97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>inventory_final</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>customer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>store_backup_</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>store</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>warehouse</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             namespace        tableName  isTemporary\n",
       "0  tpcds_10000_parquet  inventory_final        False\n",
       "1  tpcds_10000_parquet         customer        False\n",
       "2  tpcds_10000_parquet    store_backup_        False\n",
       "3  tpcds_10000_parquet            store        False\n",
       "4  tpcds_10000_parquet        warehouse        False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"show tables IN spark_catalog.tpcds_10000_parquet\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dbc7c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_warehouse_sk</th>\n",
       "      <th>w_warehouse_id</th>\n",
       "      <th>w_warehouse_name</th>\n",
       "      <th>w_warehouse_sq_ft</th>\n",
       "      <th>w_street_number</th>\n",
       "      <th>w_street_name</th>\n",
       "      <th>w_street_type</th>\n",
       "      <th>w_suite_number</th>\n",
       "      <th>w_city</th>\n",
       "      <th>w_county</th>\n",
       "      <th>w_state</th>\n",
       "      <th>w_zip</th>\n",
       "      <th>w_country</th>\n",
       "      <th>w_gmt_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>Conventional childr</td>\n",
       "      <td>977787.0</td>\n",
       "      <td>651</td>\n",
       "      <td>6th</td>\n",
       "      <td>Parkway</td>\n",
       "      <td>Suite 470</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>59231</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAAAACAAAAAAA</td>\n",
       "      <td>Important issues liv</td>\n",
       "      <td>138504.0</td>\n",
       "      <td>600</td>\n",
       "      <td>View First</td>\n",
       "      <td>Avenue</td>\n",
       "      <td>Suite P</td>\n",
       "      <td>Fairview</td>\n",
       "      <td>Walker County</td>\n",
       "      <td>AL</td>\n",
       "      <td>35709</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AAAAAAAADAAAAAAA</td>\n",
       "      <td>Doors canno</td>\n",
       "      <td>294242.0</td>\n",
       "      <td>534</td>\n",
       "      <td>Ash Laurel</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>Suite 0</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>59231</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AAAAAAAAEAAAAAAA</td>\n",
       "      <td>Bad cards must make.</td>\n",
       "      <td>621234.0</td>\n",
       "      <td>368</td>\n",
       "      <td>Wilson Elm</td>\n",
       "      <td>Drive</td>\n",
       "      <td>Suite 80</td>\n",
       "      <td>Fairview</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>55709</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AAAAAAAAFAAAAAAA</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>Walker County</td>\n",
       "      <td>AL</td>\n",
       "      <td>39231</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>AAAAAAAAGAAAAAAA</td>\n",
       "      <td>Local, mass universi</td>\n",
       "      <td>838797.0</td>\n",
       "      <td>957</td>\n",
       "      <td>Lincoln Adams</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>Suite X</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>59231</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>AAAAAAAAHAAAAAAA</td>\n",
       "      <td>Quite effectiv</td>\n",
       "      <td>662475.0</td>\n",
       "      <td>69</td>\n",
       "      <td>7th Sunset</td>\n",
       "      <td>Ct.</td>\n",
       "      <td>Suite 350</td>\n",
       "      <td>Pleasant Hill</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>53604</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>AAAAAAAAIAAAAAAA</td>\n",
       "      <td>Plain, reluctant</td>\n",
       "      <td>514427.0</td>\n",
       "      <td>410</td>\n",
       "      <td>3rd</td>\n",
       "      <td>ST</td>\n",
       "      <td>Suite 370</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>59231</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>AAAAAAAAJAAAAAAA</td>\n",
       "      <td>Rooms cook</td>\n",
       "      <td>73065.0</td>\n",
       "      <td>420</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Wy</td>\n",
       "      <td>Suite I</td>\n",
       "      <td>Oak Grove</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>58370</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>AAAAAAAAKAAAAAAA</td>\n",
       "      <td>National, comple</td>\n",
       "      <td>914242.0</td>\n",
       "      <td>269</td>\n",
       "      <td>Elm Madison</td>\n",
       "      <td>Street</td>\n",
       "      <td>Suite 90</td>\n",
       "      <td>Pleasant Hill</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>53604</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   w_warehouse_sk    w_warehouse_id      w_warehouse_name  w_warehouse_sq_ft  \\\n",
       "0               1  AAAAAAAABAAAAAAA   Conventional childr           977787.0   \n",
       "1               2  AAAAAAAACAAAAAAA  Important issues liv           138504.0   \n",
       "2               3  AAAAAAAADAAAAAAA           Doors canno           294242.0   \n",
       "3               4  AAAAAAAAEAAAAAAA  Bad cards must make.           621234.0   \n",
       "4               5  AAAAAAAAFAAAAAAA                  None                NaN   \n",
       "5               6  AAAAAAAAGAAAAAAA  Local, mass universi           838797.0   \n",
       "6               7  AAAAAAAAHAAAAAAA        Quite effectiv           662475.0   \n",
       "7               8  AAAAAAAAIAAAAAAA      Plain, reluctant           514427.0   \n",
       "8               9  AAAAAAAAJAAAAAAA           Rooms cook             73065.0   \n",
       "9              10  AAAAAAAAKAAAAAAA      National, comple           914242.0   \n",
       "\n",
       "  w_street_number  w_street_name w_street_type w_suite_number         w_city  \\\n",
       "0             651           6th        Parkway      Suite 470      Riverside   \n",
       "1             600     View First        Avenue        Suite P       Fairview   \n",
       "2             534     Ash Laurel           Dr.        Suite 0      Riverside   \n",
       "3             368     Wilson Elm         Drive       Suite 80       Fairview   \n",
       "4            None           None          None           None      Riverside   \n",
       "5             957  Lincoln Adams           Dr.        Suite X      Riverside   \n",
       "6              69     7th Sunset           Ct.      Suite 350  Pleasant Hill   \n",
       "7             410           3rd             ST      Suite 370      Riverside   \n",
       "8             420        Spring             Wy        Suite I      Oak Grove   \n",
       "9             269    Elm Madison        Street       Suite 90  Pleasant Hill   \n",
       "\n",
       "         w_county w_state  w_zip      w_country w_gmt_offset  \n",
       "0  Ziebach County      SD  59231  United States        -6.00  \n",
       "1   Walker County      AL  35709  United States        -6.00  \n",
       "2  Ziebach County      SD  59231  United States        -6.00  \n",
       "3  Ziebach County      SD  55709  United States        -6.00  \n",
       "4   Walker County      AL  39231  United States         None  \n",
       "5  Ziebach County      SD  59231  United States        -6.00  \n",
       "6  Ziebach County      SD  53604  United States        -6.00  \n",
       "7  Ziebach County      SD  59231  United States        -6.00  \n",
       "8  Ziebach County      SD  58370  United States        -6.00  \n",
       "9  Ziebach County      SD  53604  United States        -6.00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"Select * from spark_catalog.tpcds_10000_parquet.warehouse limit 10 \").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c276c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"ALTER TABLE spark_catalog.tpcds_10000_parquet.inventory_final PARTITION (inv_date_sk=2450850) set location 's3a://warehouse/tablespace/external/hive/tpcds_10000_parquet.db/inventory_final/inv_date_sk=2450850' \")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "021acf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inv_item_sk</td>\n",
       "      <td>int</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inv_warehouse_sk</td>\n",
       "      <td>int</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inv_quantity_on_hand</td>\n",
       "      <td>int</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inv_date_sk</td>\n",
       "      <td>int</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># Partition Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td># col_name</td>\n",
       "      <td>data_type</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inv_date_sk</td>\n",
       "      <td>int</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td># Detailed Partition Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Database</td>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Table</td>\n",
       "      <td>inventory_final</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Partition Values</td>\n",
       "      <td>[inv_date_sk=2450815]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Location</td>\n",
       "      <td>hdfs://master1.hadoop.com:8020/warehouse/table...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Serde Library</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.parquet.serde.Par...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>InputFormat</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.parquet.MapredPar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OutputFormat</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.parquet.MapredPar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Storage Properties</td>\n",
       "      <td>[serialization.format=1]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Partition Parameters</td>\n",
       "      <td>{rawDataSize=1530000, numFiles=1, numFilesEras...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Created Time</td>\n",
       "      <td>Thu Jan 01 00:00:00 WET 1970</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Last Access</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Partition Statistics</td>\n",
       "      <td>2715443 bytes, 510000 rows</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td># Storage Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Location</td>\n",
       "      <td>s3a://migration/tablespace/external/hive/tpcds...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Serde Library</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.parquet.serde.Par...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>InputFormat</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.parquet.MapredPar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OutputFormat</td>\n",
       "      <td>org.apache.hadoop.hive.ql.io.parquet.MapredPar...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Storage Properties</td>\n",
       "      <td>[serialization.format=1]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            col_name  \\\n",
       "0                        inv_item_sk   \n",
       "1                   inv_warehouse_sk   \n",
       "2               inv_quantity_on_hand   \n",
       "3                        inv_date_sk   \n",
       "4            # Partition Information   \n",
       "5                         # col_name   \n",
       "6                        inv_date_sk   \n",
       "7                                      \n",
       "8   # Detailed Partition Information   \n",
       "9                           Database   \n",
       "10                             Table   \n",
       "11                  Partition Values   \n",
       "12                          Location   \n",
       "13                     Serde Library   \n",
       "14                       InputFormat   \n",
       "15                      OutputFormat   \n",
       "16                Storage Properties   \n",
       "17              Partition Parameters   \n",
       "18                      Created Time   \n",
       "19                       Last Access   \n",
       "20              Partition Statistics   \n",
       "21                                     \n",
       "22             # Storage Information   \n",
       "23                          Location   \n",
       "24                     Serde Library   \n",
       "25                       InputFormat   \n",
       "26                      OutputFormat   \n",
       "27                Storage Properties   \n",
       "\n",
       "                                            data_type  comment  \n",
       "0                                                 int     None  \n",
       "1                                                 int     None  \n",
       "2                                                 int     None  \n",
       "3                                                 int     None  \n",
       "4                                                               \n",
       "5                                           data_type  comment  \n",
       "6                                                 int     None  \n",
       "7                                                               \n",
       "8                                                               \n",
       "9                                 tpcds_10000_parquet           \n",
       "10                                    inventory_final           \n",
       "11                              [inv_date_sk=2450815]           \n",
       "12  hdfs://master1.hadoop.com:8020/warehouse/table...           \n",
       "13  org.apache.hadoop.hive.ql.io.parquet.serde.Par...           \n",
       "14  org.apache.hadoop.hive.ql.io.parquet.MapredPar...           \n",
       "15  org.apache.hadoop.hive.ql.io.parquet.MapredPar...           \n",
       "16                           [serialization.format=1]           \n",
       "17  {rawDataSize=1530000, numFiles=1, numFilesEras...           \n",
       "18                       Thu Jan 01 00:00:00 WET 1970           \n",
       "19                                            UNKNOWN           \n",
       "20                         2715443 bytes, 510000 rows           \n",
       "21                                                              \n",
       "22                                                              \n",
       "23  s3a://migration/tablespace/external/hive/tpcds...           \n",
       "24  org.apache.hadoop.hive.ql.io.parquet.serde.Par...           \n",
       "25  org.apache.hadoop.hive.ql.io.parquet.MapredPar...           \n",
       "26  org.apache.hadoop.hive.ql.io.parquet.MapredPar...           \n",
       "27                           [serialization.format=1]           "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\" describe formatted spark_catalog.tpcds_10000_parquet.inventory_final PARTITION (inv_date_sk=2450815) \").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e09d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed command for inv_date_sk=2450815\n",
      "Executed command for inv_date_sk=2450822\n",
      "Executed command for inv_date_sk=2450829\n",
      "Executed command for inv_date_sk=2450836\n",
      "Executed command for inv_date_sk=2450843\n",
      "Executed command for inv_date_sk=2450850\n",
      "Executed command for inv_date_sk=2450857\n",
      "Executed command for inv_date_sk=2450864\n",
      "Executed command for inv_date_sk=2450871\n",
      "Executed command for inv_date_sk=2450878\n",
      "Executed command for inv_date_sk=2450885\n",
      "Executed command for inv_date_sk=2450892\n",
      "Executed command for inv_date_sk=2450899\n",
      "Executed command for inv_date_sk=2450906\n",
      "Executed command for inv_date_sk=2450913\n",
      "Executed command for inv_date_sk=2450920\n",
      "Executed command for inv_date_sk=2450927\n",
      "Executed command for inv_date_sk=2450934\n",
      "Executed command for inv_date_sk=2450941\n",
      "Executed command for inv_date_sk=2450948\n",
      "Executed command for inv_date_sk=2450955\n",
      "Executed command for inv_date_sk=2450962\n",
      "Executed command for inv_date_sk=2450969\n",
      "Executed command for inv_date_sk=2450976\n",
      "Executed command for inv_date_sk=2450983\n",
      "Executed command for inv_date_sk=2450990\n",
      "Executed command for inv_date_sk=2450997\n",
      "Executed command for inv_date_sk=2451004\n",
      "Executed command for inv_date_sk=2451011\n",
      "Executed command for inv_date_sk=2451018\n",
      "Executed command for inv_date_sk=2451025\n",
      "Executed command for inv_date_sk=2451032\n",
      "Executed command for inv_date_sk=2451039\n",
      "Executed command for inv_date_sk=2451046\n",
      "Executed command for inv_date_sk=2451053\n",
      "Executed command for inv_date_sk=2451060\n",
      "Executed command for inv_date_sk=2451067\n",
      "Executed command for inv_date_sk=2451074\n",
      "Executed command for inv_date_sk=2451081\n",
      "Executed command for inv_date_sk=2451088\n",
      "Executed command for inv_date_sk=2451095\n",
      "Executed command for inv_date_sk=2451102\n",
      "Executed command for inv_date_sk=2451109\n",
      "Executed command for inv_date_sk=2451116\n",
      "Executed command for inv_date_sk=2451123\n",
      "Executed command for inv_date_sk=2451130\n",
      "Executed command for inv_date_sk=2451137\n",
      "Executed command for inv_date_sk=2451144\n",
      "Executed command for inv_date_sk=2451151\n",
      "Executed command for inv_date_sk=2451158\n",
      "Executed command for inv_date_sk=2451165\n",
      "Executed command for inv_date_sk=2451172\n",
      "Executed command for inv_date_sk=2451179\n",
      "Executed command for inv_date_sk=2451186\n",
      "Executed command for inv_date_sk=2451193\n",
      "Executed command for inv_date_sk=2451200\n",
      "Executed command for inv_date_sk=2451207\n",
      "Executed command for inv_date_sk=2451214\n",
      "Executed command for inv_date_sk=2451221\n",
      "Executed command for inv_date_sk=2451228\n",
      "Executed command for inv_date_sk=2451235\n",
      "Executed command for inv_date_sk=2451242\n",
      "Executed command for inv_date_sk=2451249\n",
      "Executed command for inv_date_sk=2451256\n",
      "Executed command for inv_date_sk=2451263\n",
      "Executed command for inv_date_sk=2451270\n",
      "Executed command for inv_date_sk=2451277\n",
      "Executed command for inv_date_sk=2451284\n",
      "Executed command for inv_date_sk=2451291\n",
      "Executed command for inv_date_sk=2451298\n",
      "Executed command for inv_date_sk=2451305\n",
      "Executed command for inv_date_sk=2451312\n",
      "Executed command for inv_date_sk=2451319\n",
      "Executed command for inv_date_sk=2451326\n",
      "Executed command for inv_date_sk=2451333\n",
      "Executed command for inv_date_sk=2451340\n",
      "Executed command for inv_date_sk=2451347\n",
      "Executed command for inv_date_sk=2451354\n",
      "Executed command for inv_date_sk=2451361\n",
      "Executed command for inv_date_sk=2451368\n",
      "Executed command for inv_date_sk=2451375\n",
      "Executed command for inv_date_sk=2451382\n",
      "Executed command for inv_date_sk=2451389\n",
      "Executed command for inv_date_sk=2451396\n",
      "Executed command for inv_date_sk=2451403\n",
      "Executed command for inv_date_sk=2451410\n",
      "Executed command for inv_date_sk=2451417\n",
      "Executed command for inv_date_sk=2451424\n",
      "Executed command for inv_date_sk=2451431\n",
      "Executed command for inv_date_sk=2451438\n",
      "Executed command for inv_date_sk=2451445\n",
      "Executed command for inv_date_sk=2451452\n",
      "Executed command for inv_date_sk=2451459\n",
      "Executed command for inv_date_sk=2451466\n",
      "Executed command for inv_date_sk=2451473\n",
      "Executed command for inv_date_sk=2451480\n",
      "Executed command for inv_date_sk=2451487\n",
      "Executed command for inv_date_sk=2451494\n",
      "Executed command for inv_date_sk=2451501\n",
      "Executed command for inv_date_sk=2451508\n",
      "Executed command for inv_date_sk=2451515\n",
      "Executed command for inv_date_sk=2451522\n",
      "Executed command for inv_date_sk=2451529\n",
      "Executed command for inv_date_sk=2451536\n",
      "Executed command for inv_date_sk=2451543\n",
      "Executed command for inv_date_sk=2451550\n",
      "Executed command for inv_date_sk=2451557\n",
      "Executed command for inv_date_sk=2451564\n",
      "Executed command for inv_date_sk=2451571\n",
      "Executed command for inv_date_sk=2451578\n",
      "Executed command for inv_date_sk=2451585\n",
      "Executed command for inv_date_sk=2451592\n",
      "Executed command for inv_date_sk=2451599\n",
      "Executed command for inv_date_sk=2451606\n",
      "Executed command for inv_date_sk=2451613\n",
      "Executed command for inv_date_sk=2451620\n",
      "Executed command for inv_date_sk=2451627\n",
      "Executed command for inv_date_sk=2451634\n",
      "Executed command for inv_date_sk=2451641\n",
      "Executed command for inv_date_sk=2451648\n",
      "Executed command for inv_date_sk=2451655\n",
      "Executed command for inv_date_sk=2451662\n",
      "Executed command for inv_date_sk=2451669\n",
      "Executed command for inv_date_sk=2451676\n",
      "Executed command for inv_date_sk=2451683\n",
      "Executed command for inv_date_sk=2451690\n",
      "Executed command for inv_date_sk=2451697\n",
      "Executed command for inv_date_sk=2451704\n",
      "Executed command for inv_date_sk=2451711\n",
      "Executed command for inv_date_sk=2451718\n",
      "Executed command for inv_date_sk=2451725\n",
      "Executed command for inv_date_sk=2451732\n",
      "Executed command for inv_date_sk=2451739\n",
      "Executed command for inv_date_sk=2451746\n",
      "Executed command for inv_date_sk=2451753\n",
      "Executed command for inv_date_sk=2451760\n",
      "Executed command for inv_date_sk=2451767\n",
      "Executed command for inv_date_sk=2451774\n",
      "Executed command for inv_date_sk=2451781\n",
      "Executed command for inv_date_sk=2451788\n",
      "Executed command for inv_date_sk=2451795\n",
      "Executed command for inv_date_sk=2451802\n",
      "Executed command for inv_date_sk=2451809\n",
      "Executed command for inv_date_sk=2451816\n",
      "Executed command for inv_date_sk=2451823\n",
      "Executed command for inv_date_sk=2451830\n",
      "Executed command for inv_date_sk=2451837\n",
      "Executed command for inv_date_sk=2451844\n",
      "Executed command for inv_date_sk=2451851\n",
      "Executed command for inv_date_sk=2451858\n",
      "Executed command for inv_date_sk=2451865\n",
      "Executed command for inv_date_sk=2451872\n",
      "Executed command for inv_date_sk=2451879\n",
      "Executed command for inv_date_sk=2451886\n",
      "Executed command for inv_date_sk=2451893\n",
      "Executed command for inv_date_sk=2451900\n",
      "Executed command for inv_date_sk=2451907\n",
      "Executed command for inv_date_sk=2451914\n",
      "Executed command for inv_date_sk=2451921\n",
      "Executed command for inv_date_sk=2451928\n",
      "Executed command for inv_date_sk=2451935\n",
      "Executed command for inv_date_sk=2451942\n",
      "Executed command for inv_date_sk=2451949\n",
      "Executed command for inv_date_sk=2451956\n",
      "Executed command for inv_date_sk=2451963\n",
      "Executed command for inv_date_sk=2451970\n",
      "Executed command for inv_date_sk=2451977\n",
      "Executed command for inv_date_sk=2451984\n",
      "Executed command for inv_date_sk=2451991\n",
      "Executed command for inv_date_sk=2451998\n",
      "Executed command for inv_date_sk=2452005\n",
      "Executed command for inv_date_sk=2452012\n",
      "Executed command for inv_date_sk=2452019\n",
      "Executed command for inv_date_sk=2452026\n",
      "Executed command for inv_date_sk=2452033\n",
      "Executed command for inv_date_sk=2452040\n",
      "Executed command for inv_date_sk=2452047\n",
      "Executed command for inv_date_sk=2452054\n",
      "Executed command for inv_date_sk=2452061\n",
      "Executed command for inv_date_sk=2452068\n",
      "Executed command for inv_date_sk=2452075\n",
      "Executed command for inv_date_sk=2452082\n",
      "Executed command for inv_date_sk=2452089\n",
      "Executed command for inv_date_sk=2452096\n",
      "Executed command for inv_date_sk=2452103\n",
      "Executed command for inv_date_sk=2452110\n",
      "Executed command for inv_date_sk=2452117\n",
      "Executed command for inv_date_sk=2452124\n",
      "Executed command for inv_date_sk=2452131\n",
      "Executed command for inv_date_sk=2452138\n",
      "Executed command for inv_date_sk=2452145\n",
      "Executed command for inv_date_sk=2452152\n",
      "Executed command for inv_date_sk=2452159\n",
      "Executed command for inv_date_sk=2452166\n",
      "Executed command for inv_date_sk=2452173\n",
      "Executed command for inv_date_sk=2452180\n",
      "Executed command for inv_date_sk=2452187\n",
      "Executed command for inv_date_sk=2452194\n",
      "Executed command for inv_date_sk=2452201\n",
      "Executed command for inv_date_sk=2452208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed command for inv_date_sk=2452215\n",
      "Executed command for inv_date_sk=2452222\n",
      "Executed command for inv_date_sk=2452229\n",
      "Executed command for inv_date_sk=2452236\n",
      "Executed command for inv_date_sk=2452243\n",
      "Executed command for inv_date_sk=2452250\n",
      "Executed command for inv_date_sk=2452257\n",
      "Executed command for inv_date_sk=2452264\n",
      "Executed command for inv_date_sk=2452271\n",
      "Executed command for inv_date_sk=2452278\n",
      "Executed command for inv_date_sk=2452285\n",
      "Executed command for inv_date_sk=2452292\n",
      "Executed command for inv_date_sk=2452299\n",
      "Executed command for inv_date_sk=2452306\n",
      "Executed command for inv_date_sk=2452313\n",
      "Executed command for inv_date_sk=2452320\n",
      "Executed command for inv_date_sk=2452327\n",
      "Executed command for inv_date_sk=2452334\n",
      "Executed command for inv_date_sk=2452341\n",
      "Executed command for inv_date_sk=2452348\n",
      "Executed command for inv_date_sk=2452355\n",
      "Executed command for inv_date_sk=2452362\n",
      "Executed command for inv_date_sk=2452369\n",
      "Executed command for inv_date_sk=2452376\n",
      "Executed command for inv_date_sk=2452383\n",
      "Executed command for inv_date_sk=2452390\n",
      "Executed command for inv_date_sk=2452397\n",
      "Executed command for inv_date_sk=2452404\n",
      "Executed command for inv_date_sk=2452411\n",
      "Executed command for inv_date_sk=2452418\n",
      "Executed command for inv_date_sk=2452425\n",
      "Executed command for inv_date_sk=2452432\n",
      "Executed command for inv_date_sk=2452439\n",
      "Executed command for inv_date_sk=2452446\n",
      "Executed command for inv_date_sk=2452453\n",
      "Executed command for inv_date_sk=2452460\n",
      "Executed command for inv_date_sk=2452467\n",
      "Executed command for inv_date_sk=2452474\n",
      "Executed command for inv_date_sk=2452481\n",
      "Executed command for inv_date_sk=2452488\n",
      "Executed command for inv_date_sk=2452495\n",
      "Executed command for inv_date_sk=2452502\n",
      "Executed command for inv_date_sk=2452509\n",
      "Executed command for inv_date_sk=2452516\n",
      "Executed command for inv_date_sk=2452523\n",
      "Executed command for inv_date_sk=2452530\n",
      "Executed command for inv_date_sk=2452537\n",
      "Executed command for inv_date_sk=2452544\n",
      "Executed command for inv_date_sk=2452551\n",
      "Executed command for inv_date_sk=2452558\n",
      "Executed command for inv_date_sk=2452565\n",
      "Executed command for inv_date_sk=2452572\n",
      "Executed command for inv_date_sk=2452579\n",
      "Executed command for inv_date_sk=2452586\n",
      "Executed command for inv_date_sk=2452593\n",
      "Executed command for inv_date_sk=2452600\n",
      "Executed command for inv_date_sk=2452607\n",
      "Executed command for inv_date_sk=2452614\n",
      "Executed command for inv_date_sk=2452621\n",
      "Executed command for inv_date_sk=2452628\n",
      "Executed command for inv_date_sk=2452635\n"
     ]
    }
   ],
   "source": [
    "base_command = \"\"\"\n",
    "ALTER TABLE spark_catalog.tpcds_10000_parquet.inventory_final \n",
    "PARTITION (inv_date_sk={inv_date_sk}) \n",
    "SET LOCATION 's3a://warehouse/tablespace/external/hive/tpcds_10000_parquet.db/inventory_final/inv_date_sk={inv_date_sk}'\n",
    "\"\"\"\n",
    "for inv_date_sk in inv_date_sk_values:\n",
    "    command = base_command.format(inv_date_sk=inv_date_sk)\n",
    "    spark.sql(command)\n",
    "    print(f\"Executed command for inv_date_sk={inv_date_sk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2f5db",
   "metadata": {},
   "source": [
    "### Show the hive/iceberg catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4faf66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iceberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spark_catalog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         catalog\n",
       "0        iceberg\n",
       "1  spark_catalog"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"show catalogs\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5aa663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             namespace\n",
       "0  tpcds_10000_parquet"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"show namespaces IN iceberg\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913119bf",
   "metadata": {},
   "source": [
    "## Migrating the Hive Table to an Iceberg Table Without Restating the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273496c1",
   "metadata": {},
   "source": [
    "## Using the migrate/add_files Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3c5001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>migrated_files_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   migrated_files_count\n",
       "0                     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"Call spark_catalog.system.migrate(table => 'tpcds_10000_parquet.warehouse')\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af70844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added_files_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   added_files_count\n",
       "0                348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CALL iceberg.system.add_files(table => 'iceberg.test.said',source_table => 'spark_catalog.tpcds_10000_parquet.inventory_final')\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bba8a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_store_sk</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_store_id</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_rec_start_date</td>\n",
       "      <td>date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_rec_end_date</td>\n",
       "      <td>date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_closed_date_sk</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s_store_name</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s_number_employees</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s_floor_space</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s_hours</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s_manager</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s_market_id</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s_geography_class</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s_market_desc</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s_market_manager</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s_division_id</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s_division_name</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s_company_id</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s_company_name</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s_street_number</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s_street_name</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s_street_type</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s_suite_number</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>s_city</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>s_county</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>s_state</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>s_zip</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s_country</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>s_gmt_offset</td>\n",
       "      <td>decimal(5,2)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>s_tax_precentage</td>\n",
       "      <td>decimal(5,2)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td># Partitioning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Not partitioned</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td># Metadata Columns</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>_spec_id</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>_partition</td>\n",
       "      <td>struct&lt;&gt;</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>_file</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>_pos</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>_deleted</td>\n",
       "      <td>boolean</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td># Detailed Table Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Name</td>\n",
       "      <td>spark_catalog.tpcds_10000_parquet.store</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Location</td>\n",
       "      <td>s3a://warehouse/tablespace/external/hive/tpcds...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Provider</td>\n",
       "      <td>iceberg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Table Properties</td>\n",
       "      <td>[bucketing_version=2,current-snapshot-id=19254...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col_name  \\\n",
       "0                     s_store_sk   \n",
       "1                     s_store_id   \n",
       "2               s_rec_start_date   \n",
       "3                 s_rec_end_date   \n",
       "4               s_closed_date_sk   \n",
       "5                   s_store_name   \n",
       "6             s_number_employees   \n",
       "7                  s_floor_space   \n",
       "8                        s_hours   \n",
       "9                      s_manager   \n",
       "10                   s_market_id   \n",
       "11             s_geography_class   \n",
       "12                 s_market_desc   \n",
       "13              s_market_manager   \n",
       "14                 s_division_id   \n",
       "15               s_division_name   \n",
       "16                  s_company_id   \n",
       "17                s_company_name   \n",
       "18               s_street_number   \n",
       "19                 s_street_name   \n",
       "20                 s_street_type   \n",
       "21                s_suite_number   \n",
       "22                        s_city   \n",
       "23                      s_county   \n",
       "24                       s_state   \n",
       "25                         s_zip   \n",
       "26                     s_country   \n",
       "27                  s_gmt_offset   \n",
       "28              s_tax_precentage   \n",
       "29                                 \n",
       "30                # Partitioning   \n",
       "31               Not partitioned   \n",
       "32                                 \n",
       "33            # Metadata Columns   \n",
       "34                      _spec_id   \n",
       "35                    _partition   \n",
       "36                         _file   \n",
       "37                          _pos   \n",
       "38                      _deleted   \n",
       "39                                 \n",
       "40  # Detailed Table Information   \n",
       "41                          Name   \n",
       "42                      Location   \n",
       "43                      Provider   \n",
       "44              Table Properties   \n",
       "\n",
       "                                            data_type comment  \n",
       "0                                                 int          \n",
       "1                                              string          \n",
       "2                                                date          \n",
       "3                                                date          \n",
       "4                                                 int          \n",
       "5                                              string          \n",
       "6                                                 int          \n",
       "7                                                 int          \n",
       "8                                              string          \n",
       "9                                              string          \n",
       "10                                                int          \n",
       "11                                             string          \n",
       "12                                             string          \n",
       "13                                             string          \n",
       "14                                                int          \n",
       "15                                             string          \n",
       "16                                                int          \n",
       "17                                             string          \n",
       "18                                             string          \n",
       "19                                             string          \n",
       "20                                             string          \n",
       "21                                             string          \n",
       "22                                             string          \n",
       "23                                             string          \n",
       "24                                             string          \n",
       "25                                             string          \n",
       "26                                             string          \n",
       "27                                       decimal(5,2)          \n",
       "28                                       decimal(5,2)          \n",
       "29                                                             \n",
       "30                                                             \n",
       "31                                                             \n",
       "32                                                             \n",
       "33                                                             \n",
       "34                                                int          \n",
       "35                                           struct<>          \n",
       "36                                             string          \n",
       "37                                             bigint          \n",
       "38                                            boolean          \n",
       "39                                                             \n",
       "40                                                             \n",
       "41            spark_catalog.tpcds_10000_parquet.store          \n",
       "42  s3a://warehouse/tablespace/external/hive/tpcds...          \n",
       "43                                            iceberg          \n",
       "44  [bucketing_version=2,current-snapshot-id=19254...          "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.sql(\"desc formatted tpcds_10000_parquet.store\").toPandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b62c8f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[bucketing_version=2,current-snapshot-id=1925497414336440487,format=iceberg/parquet,format-version=1,last_modified_by=hive,last_modified_time=1719915093,migrated=true,numFilesErasureCoded=0,schema.name-mapping.default=[ {\\n  \"field-id\" : 1,\\n  \"names\" : [ \"s_store_sk\" ]\\n}, {\\n  \"field-id\" : 2,\\n  \"names\" : [ \"s_store_id\" ]\\n}, {\\n  \"field-id\" : 3,\\n  \"names\" : [ \"s_rec_start_date\" ]\\n}, {\\n  \"field-id\" : 4,\\n  \"names\" : [ \"s_rec_end_date\" ]\\n}, {\\n  \"field-id\" : 5,\\n  \"names\" : [ \"s_closed_date_sk\" ]\\n}, {\\n  \"field-id\" : 6,\\n  \"names\" : [ \"s_store_name\" ]\\n}, {\\n  \"field-id\" : 7,\\n  \"names\" : [ \"s_number_employees\" ]\\n}, {\\n  \"field-id\" : 8,\\n  \"names\" : [ \"s_floor_space\" ]\\n}, {\\n  \"field-id\" : 9,\\n  \"names\" : [ \"s_hours\" ]\\n}, {\\n  \"field-id\" : 10,\\n  \"names\" : [ \"s_manager\" ]\\n}, {\\n  \"field-id\" : 11,\\n  \"names\" : [ \"s_market_id\" ]\\n}, {\\n  \"field-id\" : 12,\\n  \"names\" : [ \"s_geography_class\" ]\\n}, {\\n  \"field-id\" : 13,\\n  \"names\" : [ \"s_market_desc\" ]\\n}, {\\n  \"field-id\" : 14,\\n  \"names\" : [ \"s_market_manager\" ]\\n}, {\\n  \"field-id\" : 15,\\n  \"names\" : [ \"s_division_id\" ]\\n}, {\\n  \"field-id\" : 16,\\n  \"names\" : [ \"s_division_name\" ]\\n}, {\\n  \"field-id\" : 17,\\n  \"names\" : [ \"s_company_id\" ]\\n}, {\\n  \"field-id\" : 18,\\n  \"names\" : [ \"s_company_name\" ]\\n}, {\\n  \"field-id\" : 19,\\n  \"names\" : [ \"s_street_number\" ]\\n}, {\\n  \"field-id\" : 20,\\n  \"names\" : [ \"s_street_name\" ]\\n}, {\\n  \"field-id\" : 21,\\n  \"names\" : [ \"s_street_type\" ]\\n}, {\\n  \"field-id\" : 22,\\n  \"names\" : [ \"s_suite_number\" ]\\n}, {\\n  \"field-id\" : 23,\\n  \"names\" : [ \"s_city\" ]\\n}, {\\n  \"field-id\" : 24,\\n  \"names\" : [ \"s_county\" ]\\n}, {\\n  \"field-id\" : 25,\\n  \"names\" : [ \"s_state\" ]\\n}, {\\n  \"field-id\" : 26,\\n  \"names\" : [ \"s_zip\" ]\\n}, {\\n  \"field-id\" : 27,\\n  \"names\" : [ \"s_country\" ]\\n}, {\\n  \"field-id\" : 28,\\n  \"names\" : [ \"s_gmt_offset\" ]\\n}, {\\n  \"field-id\" : 29,\\n  \"names\" : [ \"s_tax_precentage\" ]\\n} ]]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = df[\"col_name\"] == \"Table Properties\"\n",
    "df.where(f, inplace=True)\n",
    "df.loc[44,\"data_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7086bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/07/02 12:47:19 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_store_sk</th>\n",
       "      <th>s_store_id</th>\n",
       "      <th>s_rec_start_date</th>\n",
       "      <th>s_rec_end_date</th>\n",
       "      <th>s_closed_date_sk</th>\n",
       "      <th>s_store_name</th>\n",
       "      <th>s_number_employees</th>\n",
       "      <th>s_floor_space</th>\n",
       "      <th>s_hours</th>\n",
       "      <th>s_manager</th>\n",
       "      <th>...</th>\n",
       "      <th>s_street_name</th>\n",
       "      <th>s_street_type</th>\n",
       "      <th>s_suite_number</th>\n",
       "      <th>s_city</th>\n",
       "      <th>s_county</th>\n",
       "      <th>s_state</th>\n",
       "      <th>s_zip</th>\n",
       "      <th>s_country</th>\n",
       "      <th>s_gmt_offset</th>\n",
       "      <th>s_tax_precentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAAAAABAAAAAAA</td>\n",
       "      <td>1997-03-13</td>\n",
       "      <td>None</td>\n",
       "      <td>2451189.0</td>\n",
       "      <td>ought</td>\n",
       "      <td>245</td>\n",
       "      <td>5250760</td>\n",
       "      <td>8AM-4PM</td>\n",
       "      <td>William Ward</td>\n",
       "      <td>...</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Wy</td>\n",
       "      <td>Suite 250</td>\n",
       "      <td>Pleasant Hill</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>53604</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAAAAAACAAAAAAA</td>\n",
       "      <td>1997-03-13</td>\n",
       "      <td>2000-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>able</td>\n",
       "      <td>236</td>\n",
       "      <td>5285950</td>\n",
       "      <td>8AM-4PM</td>\n",
       "      <td>Scott Smith</td>\n",
       "      <td>...</td>\n",
       "      <td>Sycamore</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>Suite 410</td>\n",
       "      <td>Midway</td>\n",
       "      <td>Ziebach County</td>\n",
       "      <td>SD</td>\n",
       "      <td>51904</td>\n",
       "      <td>United States</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AAAAAAAACAAAAAAA</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>able</td>\n",
       "      <td>236</td>\n",
       "      <td>7557959</td>\n",
       "      <td>8AM-4PM</td>\n",
       "      <td>Scott Smith</td>\n",
       "      <td>...</td>\n",
       "      <td>Park Laurel</td>\n",
       "      <td>Road</td>\n",
       "      <td>Suite T</td>\n",
       "      <td>Midway</td>\n",
       "      <td>Williamson County</td>\n",
       "      <td>TN</td>\n",
       "      <td>31904</td>\n",
       "      <td>United States</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_store_sk        s_store_id s_rec_start_date s_rec_end_date  \\\n",
       "0           1  AAAAAAAABAAAAAAA       1997-03-13           None   \n",
       "1           2  AAAAAAAACAAAAAAA       1997-03-13     2000-03-12   \n",
       "2           3  AAAAAAAACAAAAAAA       2000-03-13           None   \n",
       "\n",
       "   s_closed_date_sk s_store_name  s_number_employees  s_floor_space  s_hours  \\\n",
       "0         2451189.0        ought                 245        5250760  8AM-4PM   \n",
       "1               NaN         able                 236        5285950  8AM-4PM   \n",
       "2               NaN         able                 236        7557959  8AM-4PM   \n",
       "\n",
       "      s_manager  ...  s_street_name s_street_type s_suite_number  \\\n",
       "0  William Ward  ...        Spring             Wy      Suite 250   \n",
       "1   Scott Smith  ...      Sycamore            Dr.      Suite 410   \n",
       "2   Scott Smith  ...    Park Laurel          Road        Suite T   \n",
       "\n",
       "          s_city           s_county s_state  s_zip      s_country  \\\n",
       "0  Pleasant Hill     Ziebach County      SD  53604  United States   \n",
       "1         Midway     Ziebach County      SD  51904  United States   \n",
       "2         Midway  Williamson County      TN  31904  United States   \n",
       "\n",
       "  s_gmt_offset s_tax_precentage  \n",
       "0        -6.00             0.03  \n",
       "1        -6.00             0.03  \n",
       "2        -5.00             0.03  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('select * from tpcds_10000_parquet.store limit 3 ;').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3889e935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>inventory_final</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>customer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>store_backup_</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tpcds_10000_parquet</td>\n",
       "      <td>store</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             namespace        tableName  isTemporary\n",
       "0  tpcds_10000_parquet  inventory_final        False\n",
       "1  tpcds_10000_parquet         customer        False\n",
       "2  tpcds_10000_parquet    store_backup_        False\n",
       "3  tpcds_10000_parquet            store        False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"show tables in tpcds_10000_parquet \").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38e55faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>events</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>names</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nba</td>\n",
       "      <td>salaries</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>ara</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>customersice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>fina</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>final</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>inventorisy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>said</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>toto</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>tests</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   namespace     tableName  isTemporary\n",
       "0                   events        False\n",
       "1                    names        False\n",
       "2        nba      salaries        False\n",
       "3       test           ara        False\n",
       "4       test  customersice        False\n",
       "5       test          fina        False\n",
       "6       test         final        False\n",
       "7       test   inventorisy        False\n",
       "8       test          said        False\n",
       "9       test          toto        False\n",
       "10                   tests        False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('show tables in iceberg').toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
